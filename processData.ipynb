{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8e1a5e2d-560b-4451-8ab9-8980deae62b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install elevenlabs python-dotenv h5py -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ce06fb5e-9138-44d2-84d1-d99cf8ca41d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "from elevenlabs.client import ElevenLabs\n",
    "from elevenlabs.play import play\n",
    "import os\n",
    "import pandas as pd\n",
    "import IPython\n",
    "import string\n",
    "import re\n",
    "import shutil\n",
    "import subprocess\n",
    "import librosa\n",
    "import numpy as np\n",
    "import h5py\n",
    "from collections import Counter\n",
    "\n",
    "dot = load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b53f58b4-c33d-4eee-b7ab-8f0d3ff168a2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       (Bofalogn)Paracetamol Infusion\n",
       "1                25%+Cevit+B6+B12+20cc\n",
       "2                        25%+Poly+20cc\n",
       "3                                3-way\n",
       "4                50%+Cevit+B6+B12+20cc\n",
       "                     ...              \n",
       "1694                        ေခါင္းစႅပ္\n",
       "1695                          ေဆးထုိးခ\n",
       "1696                        ေရေႏႅးအိတ္\n",
       "1697                     ေျခေထာက္ခဲဆႅဲ\n",
       "1698                          ျကက္ဆူဆီ\n",
       "Name: med_name, Length: 1699, dtype: object"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prepare Medicine Data\n",
    "raw = pd.read_csv(\"./medicine.csv\")[\"med_name\"]\n",
    "raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9762c918-fa03-49a2-8a67-037fbcdd8385",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean Medicine Data\n",
    "clean_data = []\n",
    "raw_data = []\n",
    "punctuation = ''.join([c for c in string.punctuation if c != '-'])\n",
    "exclude = ('inj', 'tab', 'mg', 'ml', 'syp', 'mgtab', 'g', 'l', 'cc', 'dt', 'iv')\n",
    "med_one_words = ['C', 'E', 'D', 'A', 'B']\n",
    "for data in raw:\n",
    "    word = \"\"\n",
    "    for c in data:\n",
    "        if c in string.ascii_letters + '-' + string.digits:\n",
    "            word += c\n",
    "        elif c in punctuation + string.whitespace:\n",
    "            word += \" \"\n",
    "\n",
    "    if word != \"\":\n",
    "        words = word.strip().split(' ')\n",
    "\n",
    "        _words = []\n",
    "        for word in words:\n",
    "            if word.lower() not in exclude and (len(word) > 1 or word in med_one_words):\n",
    "                w_ = re.sub(r'\\b\\d+[a-zA-Z]+\\b', '', word)\n",
    "                if not w_.isdigit():\n",
    "                    _words.append(w_)\n",
    "        \n",
    "        cleaned = \" \".join(_words).strip()\n",
    "        \n",
    "        if cleaned != '':\n",
    "            clean_data.append(cleaned)\n",
    "            raw_data.append(data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4027834f-c0b3-46a2-859b-5d42557ec395",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bofalogn Paracetamol Infusion</td>\n",
       "      <td>(Bofalogn)Paracetamol Infusion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Cevit B6 B12</td>\n",
       "      <td>25%+Cevit+B6+B12+20cc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Poly</td>\n",
       "      <td>25%+Poly+20cc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3-way</td>\n",
       "      <td>3-way</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Cevit B6 B12</td>\n",
       "      <td>50%+Cevit+B6+B12+20cc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1670</th>\n",
       "      <td>ZyQ</td>\n",
       "      <td>ZyQ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1671</th>\n",
       "      <td>Zyrova</td>\n",
       "      <td>Zyrova 10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1672</th>\n",
       "      <td>Zyrova</td>\n",
       "      <td>Zyrova 5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1673</th>\n",
       "      <td>Zytee RB Solution</td>\n",
       "      <td>Zytee RB Solution</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1674</th>\n",
       "      <td>Zytrim</td>\n",
       "      <td>Zytrim 120mg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1675 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  0                               1\n",
       "0     Bofalogn Paracetamol Infusion  (Bofalogn)Paracetamol Infusion\n",
       "1                      Cevit B6 B12           25%+Cevit+B6+B12+20cc\n",
       "2                              Poly                   25%+Poly+20cc\n",
       "3                             3-way                           3-way\n",
       "4                      Cevit B6 B12           50%+Cevit+B6+B12+20cc\n",
       "...                             ...                             ...\n",
       "1670                            ZyQ                             ZyQ\n",
       "1671                         Zyrova                       Zyrova 10\n",
       "1672                         Zyrova                        Zyrova 5\n",
       "1673              Zytee RB Solution               Zytee RB Solution\n",
       "1674                         Zytrim                    Zytrim 120mg\n",
       "\n",
       "[1675 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compare with raw data\n",
    "pd.DataFrame(zip(clean_data, raw_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7a6920fd-08cc-4b79-a502-fd68ecdbb6bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final Clean\n",
    "clean_data = list(set(clean_data))\n",
    "clean_data.sort()\n",
    "pd.DataFrame(clean_data)\n",
    "\n",
    "with open('medicines_p.txt', 'w') as f:\n",
    "    for medicine in clean_data:\n",
    "        f.write(medicine + \" \")\n",
    "\n",
    "\n",
    "with open('medicines.txt', 'w') as f:\n",
    "    for medicine in clean_data:\n",
    "        f.write(medicine + \"\\n\")\n",
    "\n",
    "with open(\"medicines_p.txt\", 'r') as f:\n",
    "    dictionary_raw_list = f.read().split(' ')\n",
    "\n",
    "with open(\"medicines_freq.txt\", 'w') as f:\n",
    "    for word, count in Counter(dictionary_raw_list).items():\n",
    "        if word != '' and not word.isnumeric() and not word.startswith('-'):\n",
    "            f.write(f\"{word} {count}\\n\")\n",
    "\n",
    "with open(\"medicines_dict.txt\", 'w') as f:\n",
    "    for word, count in Counter(dictionary_raw_list).items():\n",
    "        if word != '' and not word.isnumeric() and not word.startswith('-'):\n",
    "            f.write(f\"{word}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6864bb6a-5c4b-4a1c-9066-53c6866a3509",
   "metadata": {},
   "source": [
    "## Generating Voice Audio with ElevenLabs Agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2bff7612-b5f8-4c15-9007-481d8bcffaf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agents\n",
    "elevenlabs = ElevenLabs(\n",
    "  api_key=os.getenv(\"ELEVENLABS_API_KEY\"),\n",
    ")\n",
    "\n",
    "voice_ids = {\n",
    "    \"Default\": \"JBFqnCBsd6RMkjVDRZzb\",\n",
    "    \"AsianMan1\": \"K8elrI3roCHJugSjT3np\",\n",
    "    \"Matilda\": \"XrExE9yKIg1WjnnlVkGX\",\n",
    "    \"Serena\": \"pMsXgVXv3BLzUgSXRplE\",\n",
    "    \"Daniel\": \"onwK4e9ZLuTAKqWW03F9\",\n",
    "    \"Will\": \"bIHbv24MWmeRgasZH58o\",\n",
    "    \"Laura\": \"FGY2WhTYpPnrIDTdsKH5\",\n",
    "    \"Roger\": \"CwhRBWXzGAHq8TQ4Fs17\",\n",
    "    \"Clara\": \"Qggl4b0xRMiqOwhPtVWT\",\n",
    "    \"Arabella\": \"Z3R5wn05IrDiVCyEkUrK\",\n",
    "    # \"Brittney\": \"pjcYQlDFKMbcOUp6F5GD\",\n",
    "    # \"Ralf Eisent\": \"A9evEp8yGjv4c3WsIKuY\",\n",
    "    # \"Trinity\": \"2qfp6zPuviqeCOZIE9RZ\",\n",
    "    # \"Julia\": \"tOuLUAIdXShmWH7PEUrU\",\n",
    "    # \"Liam\": \"TX3LPaxmHKxFdv7VOQHJ\",\n",
    "}\n",
    "\n",
    "current_voice_id = \"AsianMan1\"\n",
    "models = [\"eleven_multilingual_v2\", \"eleven_flash_v2\"]\n",
    "current_model = \"eleven_flash_v2\"\n",
    "\n",
    "def TTS(text, voice_id):\n",
    "    audio_stream = elevenlabs.text_to_speech.convert(\n",
    "        text=text,\n",
    "        voice_id=voice_id,\n",
    "        model_id=current_model,\n",
    "        output_format=\"mp3_44100_128\",\n",
    "    )\n",
    "    \n",
    "    result = bytearray()\n",
    "    \n",
    "    for chunk in audio_stream:\n",
    "        result.extend(chunk)\n",
    "    \n",
    "    return bytes(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "87790dff-e5e1-407f-8371-baf09b4bf24b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Voice Testing\n",
    "\n",
    "# audio = TTS('Celecoxid CELEC', voice_ids[current_voice_id])\n",
    "\n",
    "# with open('a.mp3', 'wb') as f:\n",
    "#     f.write(audio)\n",
    "\n",
    "# IPython.display.Audio('a.mp3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "42965782-ad98-4af5-a2f3-8e50096f6ebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Voice Generation with one voice agent for all dataset\n",
    "\n",
    "# voices_dir = os.path.join(os.getcwd(), 'voices', 'en')\n",
    "# agent_dir = os.path.join(voices_dir, current_voice_id)\n",
    "\n",
    "\n",
    "# for text in clean_data:\n",
    "    \n",
    "#     if not os.path.exists(agent_dir):\n",
    "#         os.makedirs(agent_dir)\n",
    "    \n",
    "#     audio_path = os.path.join(agent_dir, f'{text}.mp3')\n",
    "    \n",
    "#     if not os.path.exists(audio_path):\n",
    "#         audio = TTS(text, voice_ids[current_voice_id])\n",
    "    \n",
    "#         with open(audio_path, 'wb') as f:\n",
    "#             f.write(audio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b1d98678-90d2-41dd-9678-3ad6d000e008",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Voice Generation for one text for all agent\n",
    "\n",
    "# text = \"Paracetamol\"\n",
    "# voices_dir = os.path.join(os.getcwd(), 'voices', 'en')\n",
    "\n",
    "# for voice_id in voice_ids.keys():\n",
    "#     agent_dir = os.path.join(voices_dir, voice_id)\n",
    "\n",
    "#     if not os.path.exists(agent_dir):\n",
    "#         os.makedirs(agent_dir)\n",
    "    \n",
    "#     audio_path = os.path.join(agent_dir, f'{text}.mp3')\n",
    "    \n",
    "#     if not os.path.exists(audio_path):\n",
    "#         audio = TTS(text, voice_ids[voice_id])\n",
    "    \n",
    "#         with open(audio_path, 'wb') as f:\n",
    "#             f.write(audio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1908ae1f-e594-4c6b-b711-f11d447d705b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create ASR dataset for one word\n",
    "\n",
    "# voices_dir = os.path.join(os.getcwd(), 'voices', 'en')\n",
    "# dataset_path = os.path.join(voices_dir, 'dataset')\n",
    "# data_path = os.path.join(dataset_path, 'audio')\n",
    "# metadata_path = os.path.join(dataset_path, 'metadata.csv')\n",
    "# meta_data_write_method = 'w'\n",
    "\n",
    "# text = \"Paracetamol\"\n",
    "\n",
    "# if os.path.exists(metadata_path) and meta_data_write_method != 'w':\n",
    "#     metadata_file = open(metadata_path,  meta_data_write_method)\n",
    "# else:\n",
    "#     metadata_file = open(metadata_path, 'w')\n",
    "#     metadata_file.write('file,text\\n')\n",
    "\n",
    "# if not os.path.exists(dataset_path):\n",
    "#     os.makedirs(dataset_path)\n",
    "\n",
    "# if not os.path.exists(data_path):\n",
    "#     os.makedirs(data_path)\n",
    "\n",
    "# for voice_id in voice_ids.keys():\n",
    "#     agent_dir = os.path.join(voices_dir, voice_id)\n",
    "\n",
    "#     if not os.path.exists(agent_dir):\n",
    "#         os.makedirs(agent_dir)\n",
    "    \n",
    "#     audio_path = os.path.join(agent_dir, f'{text}.mp3')\n",
    "#     target_path = os.path.join(data_path, f\"{text}.mp3\")\n",
    "#     target_path_wav = os.path.join(data_path, f\"{text}_{voice_id}.wav\")\n",
    "    \n",
    "#     if os.path.exists(audio_path) and not os.path.exists(target_path):\n",
    "#         shutil.copy(audio_path, target_path)\n",
    "#         try:\n",
    "#             subprocess.run([\"ffmpeg\", \"-i\", target_path, target_path_wav], \n",
    "#                            stdout=subprocess.DEVNULL, \n",
    "#                            stderr=subprocess.DEVNULL, \n",
    "#                            check=True) # convert to wav\n",
    "#             os.remove(target_path) # remove mp3\n",
    "#             metadata_file.write(f\"{text}_{voice_id}.wav,{text}\\n\") # csv\n",
    "#         except subprocess.CalledProcessError as e:\n",
    "#             print(\"Error:\", e.stderr)\n",
    "\n",
    "\n",
    "# metadata_file.close()\n",
    "# pd.read_csv(metadata_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "064ae72b-6f0f-4be2-abef-21404e5a5566",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create ASR dataset\n",
    "\n",
    "# voices_dir = os.path.join(os.getcwd(), 'voices', 'en')\n",
    "# dataset_path = os.path.join(voices_dir, 'dataset')\n",
    "# data_path = os.path.join(dataset_path, 'audio')\n",
    "# metadata_path = os.path.join(dataset_path, 'metadata.csv')\n",
    "# meta_data_write_method = 'w'\n",
    "\n",
    "\n",
    "# start = 0\n",
    "# end = 1483\n",
    "\n",
    "\n",
    "# metadata_file = open(metadata_path, 'w')\n",
    "# metadata_file.write('file,text\\n')\n",
    "\n",
    "# for i in range(start, end+1):\n",
    "\n",
    "#     text = clean_data[i]\n",
    "   \n",
    "#     if not os.path.exists(dataset_path):\n",
    "#         os.makedirs(dataset_path)\n",
    "   \n",
    "#     if not os.path.exists(data_path):\n",
    "#         os.makedirs(data_path)\n",
    "   \n",
    "#     for voice_id in voice_ids.keys():\n",
    "#         agent_dir = os.path.join(voices_dir, voice_id)\n",
    "   \n",
    "#         if not os.path.exists(agent_dir):\n",
    "#             os.makedirs(agent_dir)\n",
    "       \n",
    "#         audio_path = os.path.join(agent_dir, f'{text}.mp3')\n",
    "#         target_path = os.path.join(data_path, f\"{text}.mp3\")\n",
    "#         target_path_wav = os.path.join(data_path, f\"{text}_{voice_id}.wav\")\n",
    "\n",
    "#         if not os.path.exists(audio_path):\n",
    "#             generate_voice_for_all_agent(text)\n",
    "\n",
    "\n",
    "#         if os.path.exists(target_path_wav):\n",
    "#             metadata_file.write(f\"{text}_{voice_id}.wav,{text}\\n\") # csv\n",
    "       \n",
    "#         elif os.path.exists(audio_path) and not os.path.exists(target_path_wav):\n",
    "#             shutil.copy(audio_path, target_path)\n",
    "#             try:\n",
    "#                 subprocess.run([\"ffmpeg\", \"-i\", target_path, target_path_wav],\n",
    "#                                stdout=subprocess.DEVNULL,\n",
    "#                                stderr=subprocess.DEVNULL,\n",
    "#                                check=True) # convert to wav\n",
    "#                 os.remove(target_path) # remove mp3\n",
    "#                 metadata_file.write(f\"{text}_{voice_id}.wav,{text}\\n\") # csv\n",
    "#             except subprocess.CalledProcessError as e:\n",
    "#                 print(\"Error:\", e.stderr)\n",
    "\n",
    "# metadata_file.close()\n",
    "# pd.read_csv(metadata_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "584fc561-a4af-4a4b-9dd5-6f17fa95f648",
   "metadata": {},
   "source": [
    "## Saving Sample Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2cffd5ff-8ce3-476c-b758-4fd69c712612",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>audio</th>\n",
       "      <th>sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>filename</th>\n",
       "      <td>3-way_Default.wav</td>\n",
       "      <td>3-way</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>array</th>\n",
       "      <td>[-2.5507216e-10, -1.1945796e-10, -1.7387639e-1...</td>\n",
       "      <td>3-way</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sampling_rate</th>\n",
       "      <td>16000</td>\n",
       "      <td>3-way</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                           audio sentence\n",
       "filename                                       3-way_Default.wav    3-way\n",
       "array          [-2.5507216e-10, -1.1945796e-10, -1.7387639e-1...    3-way\n",
       "sampling_rate                                              16000    3-way"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Format Dataset \n",
    "\n",
    "dataset_path = os.path.join(os.getcwd(), \"voices\", \"en\", \"dataset\")\n",
    "audio_path = os.path.join(dataset_path, \"data\")\n",
    "metadata_path = os.path.join(dataset_path, \"metadata.csv\")\n",
    "metadata = pd.read_csv(metadata_path)\n",
    "\n",
    "dataset = []\n",
    "whisper_sampling_rate = 16000 # 16kHz\n",
    "total_duration = np.float32(0)\n",
    "agent_involvement = {}\n",
    "\n",
    "for filename, text in zip(metadata.file, metadata.text):\n",
    "    audio_file_path = os.path.join(audio_path, filename)\n",
    "    if os.path.exists(audio_file_path):\n",
    "        samples, sample_rate = librosa.load(audio_file_path, sr=whisper_sampling_rate)\n",
    "        total_duration += librosa.get_duration(path=audio_file_path)\n",
    "        audio = { 'audio': { 'filename': filename, 'array': samples, 'sampling_rate': sample_rate },\n",
    "                  'sentence': text\n",
    "                }\n",
    "        dataset.append(audio)\n",
    "        \n",
    "        agent = filename.split('_')[-1]\n",
    "        if agent in agent_involvement.keys():\n",
    "            agent_involvement[agent] += 1\n",
    "        else:\n",
    "            agent_involvement[agent] = 1\n",
    "    else:\n",
    "        print(audio_file_path, 'is not exits')\n",
    "\n",
    "\n",
    "pd.DataFrame(dataset[0])\n",
    "# print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0c3af55f-860f-421e-8d6f-18e4d0c3b411",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Dataset:  14669\n",
      "Total Duration (second)s:  15853.571\n",
      "No. of Agents:  10\n",
      "No. of VoiceLines:  1466\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Default.wav</td>\n",
       "      <td>1467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Matilda.wav</td>\n",
       "      <td>1467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Serena.wav</td>\n",
       "      <td>1467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Daniel.wav</td>\n",
       "      <td>1467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Will.wav</td>\n",
       "      <td>1467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Laura.wav</td>\n",
       "      <td>1467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Roger.wav</td>\n",
       "      <td>1467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Clara.wav</td>\n",
       "      <td>1467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Liam.wav</td>\n",
       "      <td>1467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>AsianMan1.wav</td>\n",
       "      <td>1466</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               0     1\n",
       "0    Default.wav  1467\n",
       "1    Matilda.wav  1467\n",
       "2     Serena.wav  1467\n",
       "3     Daniel.wav  1467\n",
       "4       Will.wav  1467\n",
       "5      Laura.wav  1467\n",
       "6      Roger.wav  1467\n",
       "7      Clara.wav  1467\n",
       "8       Liam.wav  1467\n",
       "9  AsianMan1.wav  1466"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Total Dataset: \", len(dataset))\n",
    "print(\"Total Duration (second)s: \", total_duration)\n",
    "print(\"No. of Agents: \", len(agent_involvement.keys()))\n",
    "print(\"No. of VoiceLines: \", len(dataset)//len(agent_involvement.keys()))\n",
    "pd.DataFrame(agent_involvement.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b3015c8f-d7e4-484c-a50f-0229b5b29d04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Format Dataset for HDF5\n",
    "\n",
    "# Find max length of audio sample\n",
    "max_len = max(len(d['audio']['array']) for d in dataset)\n",
    "\n",
    "# Pad all audio arrays to same length\n",
    "def pad(x, max_len):\n",
    "    return np.pad(x, (0, max_len - len(x)), mode='constant')\n",
    "\n",
    "padded_samples = np.array([pad(d['audio']['array'], max_len) for d in dataset])\n",
    "filenames = np.array([d['audio']['filename'] for d in dataset], dtype=\"S\")  # bytes\n",
    "sampling_rates = np.array([d['audio']['sampling_rate'] for d in dataset])\n",
    "sentences = np.array([d['sentence'] for d in dataset], dtype=\"S\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e442c140-729c-40ce-95b5-ff3fb3176824",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save as HDF5\n",
    "h5filename = \"medicines_whisper_en_dataset_v2.h5\"\n",
    "\n",
    "with h5py.File(h5filename, \"w\") as f:\n",
    "    f.create_dataset(\"audio/samples\", data=padded_samples)\n",
    "    f.create_dataset(\"audio/sampling_rate\", data=sampling_rates)\n",
    "    f.create_dataset(\"audio/total_duration\", data=total_duration, dtype='float32')\n",
    "    f.create_dataset(\"sentence\", data=sentences)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92298f2b-0f01-43bc-a613-160f152d9786",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be89f17f-f07b-4911-85f0-080ae5725be5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
